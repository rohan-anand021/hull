{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5fed419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "base_dir = 'hull-tactical-market-prediction'\n",
    "tr = base_dir + '/train.csv'\n",
    "te = base_dir + '/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "175b3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(tr)\n",
    "test = pl.read_csv(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca9f62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "unable to find column \"forward_returns_lag_1\"; valid columns: [\"date_id\", \"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"E1\", \"E10\", \"E11\", \"E12\", \"E13\", \"E14\", \"E15\", \"E16\", \"E17\", \"E18\", \"E19\", \"E2\", \"E20\", \"E3\", \"E4\", \"E5\", \"E6\", \"E7\", \"E8\", \"E9\", \"I1\", \"I2\", \"I3\", \"I4\", \"I5\", \"I6\", \"I7\", \"I8\", \"I9\", \"M1\", \"M10\", \"M11\", \"M12\", \"M13\", \"M14\", \"M15\", \"M16\", \"M17\", \"M18\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"P1\", \"P10\", \"P11\", \"P12\", \"P13\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"S1\", \"S10\", \"S11\", \"S12\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"V1\", \"V10\", \"V11\", \"V12\", \"V13\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\", \"forward_returns\", \"risk_free_rate\", \"market_forward_excess_returns\", \"M1_rolling_mean_5\", \"M1_rolling_mean_20\", \"M1_rolling_mean_100\", \"M2_rolling_mean_5\", \"M2_rolling_mean_20\", \"M2_rolling_mean_100\", \"M3_rolling_mean_5\", \"M3_rolling_mean_20\", \"M3_rolling_mean_100\", \"M4_rolling_mean_5\", \"M4_rolling_mean_20\", \"M4_rolling_mean_100\", \"M5_rolling_mean_5\", \"M5_rolling_mean_20\", \"M5_rolling_mean_100\", \"M6_rolling_mean_5\", \"M6_rolling_mean_20\", \"M6_rolling_mean_100\", \"M7_rolling_mean_5\", \"M7_rolling_mean_20\", \"M7_rolling_mean_100\", \"M8_rolling_mean_5\", \"M8_rolling_mean_20\", \"M8_rolling_mean_100\", \"M9_rolling_mean_5\", \"M9_rolling_mean_20\", \"M9_rolling_mean_100\", \"M10_rolling_mean_5\", \"M10_rolling_mean_20\", \"M10_rolling_mean_100\", \"M11_rolling_mean_5\", \"M11_rolling_mean_20\", \"M11_rolling_mean_100\", \"M12_rolling_mean_5\", \"M12_rolling_mean_20\", \"M12_rolling_mean_100\", \"M13_rolling_mean_5\", \"M13_rolling_mean_20\", \"M13_rolling_mean_100\", \"M14_rolling_mean_5\", \"M14_rolling_mean_20\", \"M14_rolling_mean_100\", \"M15_rolling_mean_5\", \"M15_rolling_mean_20\", \"M15_rolling_mean_100\", \"M16_rolling_mean_5\", \"M16_rolling_mean_20\", \"M16_rolling_mean_100\", \"M17_rolling_mean_5\", \"M17_rolling_mean_20\", \"M17_rolling_mean_100\", \"M18_rolling_mean_5\", \"M18_rolling_mean_20\", \"M18_rolling_mean_100\", \"M1_moving_average_ratio_20/100\", \"M2_moving_average_ratio_20/100\", \"M3_moving_average_ratio_20/100\", \"M4_moving_average_ratio_20/100\", \"M5_moving_average_ratio_20/100\", \"M6_moving_average_ratio_20/100\", \"M7_moving_average_ratio_20/100\", \"M8_moving_average_ratio_20/100\", \"M9_moving_average_ratio_20/100\", \"M10_moving_average_ratio_20/100\", \"M11_moving_average_ratio_20/100\", \"M12_moving_average_ratio_20/100\", \"M13_moving_average_ratio_20/100\", \"M14_moving_average_ratio_20/100\", \"M15_moving_average_ratio_20/100\", \"M16_moving_average_ratio_20/100\", \"M17_moving_average_ratio_20/100\", \"M18_moving_average_ratio_20/100\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mColumnNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     57\u001b[39m allocation_feature = (\n\u001b[32m     58\u001b[39m     pl.when((pl.col(\u001b[33m'\u001b[39m\u001b[33mforward_returns_lag_1\u001b[39m\u001b[33m'\u001b[39m) > \u001b[32m0\u001b[39m) & (pl.col(\u001b[33m'\u001b[39m\u001b[33mforward_returns_lag_2\u001b[39m\u001b[33m'\u001b[39m) > \u001b[32m0\u001b[39m))\n\u001b[32m     59\u001b[39m     .then(\u001b[32m1.5\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m     .alias(\u001b[33m'\u001b[39m\u001b[33mmomentum_allocation_feature\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     64\u001b[39m )\n\u001b[32m     67\u001b[39m other_feature_exprs = lag_exprs + rolling_std_exprs + zscore_exprs + [allocation_feature]\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m train = \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother_feature_exprs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m train = train.fill_null(strategy=\u001b[33m\"\u001b[39m\u001b[33mforward\u001b[39m\u001b[33m\"\u001b[39m).fill_null(strategy=\u001b[33m\"\u001b[39m\u001b[33mbackward\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m train\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hull/.venv/lib/python3.12/site-packages/polars/dataframe/frame.py:10173\u001b[39m, in \u001b[36mDataFrame.with_columns\u001b[39m\u001b[34m(self, *exprs, **named_exprs)\u001b[39m\n\u001b[32m  10046\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m  10047\u001b[39m \u001b[33;03mAdd columns to this DataFrame.\u001b[39;00m\n\u001b[32m  10048\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m  10166\u001b[39m \u001b[33;03m└─────┴──────┴───────┴──────┴───────┘\u001b[39;00m\n\u001b[32m  10167\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m  10168\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazyframe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopt_flags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QueryOptFlags\n\u001b[32m  10170\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m  10171\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  10172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m> \u001b[39m\u001b[32m10173\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mQueryOptFlags\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_eager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  10174\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hull/.venv/lib/python3.12/site-packages/polars/_utils/deprecation.py:97\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hull/.venv/lib/python3.12/site-packages/polars/lazyframe/opt_flags.py:330\u001b[39m, in \u001b[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m         optflags = cb(optflags, kwargs.pop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[32m    329\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizations\u001b[39m\u001b[33m\"\u001b[39m] = optflags\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hull/.venv/lib/python3.12/site-packages/polars/lazyframe/frame.py:2407\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[39m\n\u001b[32m   2405\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2406\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2407\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mColumnNotFoundError\u001b[39m: unable to find column \"forward_returns_lag_1\"; valid columns: [\"date_id\", \"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"E1\", \"E10\", \"E11\", \"E12\", \"E13\", \"E14\", \"E15\", \"E16\", \"E17\", \"E18\", \"E19\", \"E2\", \"E20\", \"E3\", \"E4\", \"E5\", \"E6\", \"E7\", \"E8\", \"E9\", \"I1\", \"I2\", \"I3\", \"I4\", \"I5\", \"I6\", \"I7\", \"I8\", \"I9\", \"M1\", \"M10\", \"M11\", \"M12\", \"M13\", \"M14\", \"M15\", \"M16\", \"M17\", \"M18\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"P1\", \"P10\", \"P11\", \"P12\", \"P13\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"S1\", \"S10\", \"S11\", \"S12\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"V1\", \"V10\", \"V11\", \"V12\", \"V13\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\", \"forward_returns\", \"risk_free_rate\", \"market_forward_excess_returns\", \"M1_rolling_mean_5\", \"M1_rolling_mean_20\", \"M1_rolling_mean_100\", \"M2_rolling_mean_5\", \"M2_rolling_mean_20\", \"M2_rolling_mean_100\", \"M3_rolling_mean_5\", \"M3_rolling_mean_20\", \"M3_rolling_mean_100\", \"M4_rolling_mean_5\", \"M4_rolling_mean_20\", \"M4_rolling_mean_100\", \"M5_rolling_mean_5\", \"M5_rolling_mean_20\", \"M5_rolling_mean_100\", \"M6_rolling_mean_5\", \"M6_rolling_mean_20\", \"M6_rolling_mean_100\", \"M7_rolling_mean_5\", \"M7_rolling_mean_20\", \"M7_rolling_mean_100\", \"M8_rolling_mean_5\", \"M8_rolling_mean_20\", \"M8_rolling_mean_100\", \"M9_rolling_mean_5\", \"M9_rolling_mean_20\", \"M9_rolling_mean_100\", \"M10_rolling_mean_5\", \"M10_rolling_mean_20\", \"M10_rolling_mean_100\", \"M11_rolling_mean_5\", \"M11_rolling_mean_20\", \"M11_rolling_mean_100\", \"M12_rolling_mean_5\", \"M12_rolling_mean_20\", \"M12_rolling_mean_100\", \"M13_rolling_mean_5\", \"M13_rolling_mean_20\", \"M13_rolling_mean_100\", \"M14_rolling_mean_5\", \"M14_rolling_mean_20\", \"M14_rolling_mean_100\", \"M15_rolling_mean_5\", \"M15_rolling_mean_20\", \"M15_rolling_mean_100\", \"M16_rolling_mean_5\", \"M16_rolling_mean_20\", \"M16_rolling_mean_100\", \"M17_rolling_mean_5\", \"M17_rolling_mean_20\", \"M17_rolling_mean_100\", \"M18_rolling_mean_5\", \"M18_rolling_mean_20\", \"M18_rolling_mean_100\", \"M1_moving_average_ratio_20/100\", \"M2_moving_average_ratio_20/100\", \"M3_moving_average_ratio_20/100\", \"M4_moving_average_ratio_20/100\", \"M5_moving_average_ratio_20/100\", \"M6_moving_average_ratio_20/100\", \"M7_moving_average_ratio_20/100\", \"M8_moving_average_ratio_20/100\", \"M9_moving_average_ratio_20/100\", \"M10_moving_average_ratio_20/100\", \"M11_moving_average_ratio_20/100\", \"M12_moving_average_ratio_20/100\", \"M13_moving_average_ratio_20/100\", \"M14_moving_average_ratio_20/100\", \"M15_moving_average_ratio_20/100\", \"M16_moving_average_ratio_20/100\", \"M17_moving_average_ratio_20/100\", \"M18_moving_average_ratio_20/100\"]"
     ]
    }
   ],
   "source": [
    "m_cols = [f'M{i}' for i in range(1, 19)]\n",
    "p_cols = [f'P{i}' for i in range(1, 14)]\n",
    "v_cols = [f'V{i}' for i in range(1, 14)] + ['forward_returns']\n",
    "cols_to_cast = (\n",
    "    [f'E{i}' for i in range(1, 21)] +\n",
    "    [f'I{i}' for i in range(1, 10)] +\n",
    "    m_cols +\n",
    "    [f'S{i}' for i in range(1, 13)] +\n",
    "    [f'V{i}' for i in range(1, 14)] +\n",
    "    p_cols\n",
    ")\n",
    "\n",
    "train = train.with_columns(\n",
    "    pl.col(cols_to_cast).cast(pl.Float64, strict=False)\n",
    ")\n",
    "\n",
    "windows = [5, 20, 100]\n",
    "rolling_mean_exprs = [\n",
    "    pl.col(col)\n",
    "    .rolling_mean(window_size=window, min_samples=1)\n",
    "    .alias(f'{col}_rolling_mean_{window}')\n",
    "    for col in m_cols\n",
    "    for window in windows\n",
    "]\n",
    "train = train.with_columns(rolling_mean_exprs)\n",
    "\n",
    "ratio_exprs = [\n",
    "    (pl.col(f'M{i}_rolling_mean_20') / pl.col(f'M{i}_rolling_mean_100'))\n",
    "    .alias(f'M{i}_moving_average_ratio_20/100')\n",
    "    for i in range(1, 19)\n",
    "]\n",
    "train = train.with_columns(ratio_exprs)\n",
    "\n",
    "lag_exprs = [\n",
    "    pl.col(col).shift(day)\n",
    "    .alias(f'{col}_lag_{day}')\n",
    "    for col in ['market_forward_excess_returns', 'forward_returns']\n",
    "    for day in [1, 2, 5]\n",
    "]\n",
    "\n",
    "std_window = 20\n",
    "rolling_std_exprs = [\n",
    "    pl.col(col)\n",
    "    .rolling_std(window_size=std_window, min_samples=2)\n",
    "    .alias(f'{col}_rolling_std_{std_window}')\n",
    "    for col in v_cols\n",
    "]\n",
    "\n",
    "z_window = 100\n",
    "zscore_exprs = [\n",
    "    ((pl.col(col) - pl.col(col).rolling_mean(window_size=z_window, min_samples=1))\n",
    "     / pl.col(col).rolling_std(window_size=z_window, min_samples=2))\n",
    "    .alias(f'{col}_zscore_{z_window}')\n",
    "    for col in p_cols\n",
    "]\n",
    "\n",
    "independent_features = lag_exprs + rolling_std_exprs + zscore_exprs\n",
    "train = train.with_columns(independent_features)\n",
    "\n",
    "allocation_feature = (\n",
    "    pl.when((pl.col('forward_returns_lag_1') > 0) & (pl.col('forward_returns_lag_2') > 0))\n",
    "    .then(1.5)\n",
    "    .when(pl.col('forward_returns_lag_1') < 0)\n",
    "    .then(0.5)\n",
    "    .otherwise(1.0)\n",
    "    .alias('momentum_allocation_feature')\n",
    ")\n",
    "\n",
    "train = train.with_columns(allocation_feature)\n",
    "\n",
    "train = train.fill_null(strategy=\"forward\").fill_null(strategy=\"backward\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613b02f",
   "metadata": {},
   "source": [
    "date_id - An identifier for a single trading day.\n",
    "\n",
    "M* - Market Dynamics/Technical features.\n",
    "\n",
    "E* - Macro Economic features.\n",
    "\n",
    "I* - Interest Rate features.\n",
    "\n",
    "P* - Price/Valuation features.\n",
    "\n",
    "V* - Volatility features.\n",
    "\n",
    "S* - Sentiment features.\n",
    "\n",
    "MOM* - Momentum features.\n",
    "\n",
    "D* - Dummy/Binary features.\n",
    "\n",
    "forward_returns - The returns from buying the S&P 500 and selling it a day later. Train set only.\n",
    "\n",
    "risk_free_rate - The federal funds rate. Train set only. \n",
    "\n",
    "market_forward_excess_returns - Forward returns relative to expectations. \n",
    "Computed by subtracting the rolling five-year mean forward returns and winsorizing the result using a median absolute deviation (MAD) with a criterion of 4. Train set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05197dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score at alpha 0.001: 0.05395748906251929\n",
      "Test score at alpha 0.001: -113.62522612308982\n",
      "Train score at alpha 0.01: 0.053945960763281176\n",
      "Test score at alpha 0.01: -94.38131150033021\n",
      "Train score at alpha 1: 0.05300282581735061\n",
      "Test score at alpha 1: -2.103509156204347\n",
      "Train score at alpha 10: 0.05098960708762945\n",
      "Test score at alpha 10: -11.436165348256411\n",
      "Train score at alpha 100: 0.04582201880138426\n",
      "Test score at alpha 100: -14.258967584923722\n",
      "Train score at alpha 1000: 0.035692610936638225\n",
      "Test score at alpha 1000: -8.472851243772427\n",
      "Train score at alpha 10000: 0.019494855532804056\n",
      "Test score at alpha 10000: -0.6152066704804546\n"
     ]
    }
   ],
   "source": [
    "#ridge model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = train.select(\n",
    "    pl.exclude([\n",
    "        'date_id', \n",
    "        'market_forward_excess_returns', \n",
    "        'forward_returns',                 \n",
    "        'risk_free_rate'                   \n",
    "    ])\n",
    ")\n",
    "target = train.select(['market_forward_excess_returns'])\n",
    "\n",
    "split = int(train.height * 0.8)\n",
    "\n",
    "X_train = features.head(split).to_numpy()\n",
    "y_train = target.head(split).to_numpy().ravel()\n",
    "X_test = features.tail(-split).to_numpy()\n",
    "y_test = target.tail(-split).to_numpy().ravel()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "for a in [0.001, 0.01, 1, 10, 100, 1000, 10000]:\n",
    "    ridge = Ridge(alpha=a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "\n",
    "    train_score = ridge.score(X_train, y_train)\n",
    "    test_score = ridge.score(X_test, y_test)\n",
    "\n",
    "    print(f'Train score at alpha {a}: {train_score}', flush = True)\n",
    "    print(f'Test score at alpha {a}: {test_score}', flush = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cc47dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45638\n",
      "[LightGBM] [Info] Number of data points in the train set: 7192, number of used features: 196\n",
      "[LightGBM] [Info] Start training from score 0.000014\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.0111117\tvalid_0's l2: 0.00012347\n",
      "RMSE: 0.011111692452367193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohananand/Desktop/hull/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'n_jobs': 1\n",
    "}\n",
    "\n",
    "lgbm = lgb.LGBMRegressor(**params)\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set = [(X_test, y_test)],\n",
    "    eval_metric = 'rmse',\n",
    "    callbacks = [lgb.early_stopping(100, verbose = True)]\n",
    ")\n",
    "\n",
    "y_pred = lgbm.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb57262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scaling factor: 730\n",
      "Best score: 0.6477349220761722\n"
     ]
    }
   ],
   "source": [
    "#raw predictions - y_pred\n",
    "\n",
    "scaling_factors = range(0, 1000, 5)\n",
    "solution_pl = train.tail(-split).select(['forward_returns', 'risk_free_rate'])\n",
    "\n",
    "best_score = -np.inf\n",
    "best_factor = 0\n",
    "results = []\n",
    "\n",
    "for factor in scaling_factors:\n",
    "    allocations = np.clip((1 + (y_pred * factor)), 0, 2)\n",
    "    #allocations = (2) / (1 + np.exp(-y_pred * factor))\n",
    "    submission_pl = pl.DataFrame({\n",
    "        'prediction': allocations\n",
    "    })\n",
    "    \n",
    "    curr_score = score(\n",
    "        solution = solution_pl.to_pandas(),\n",
    "        submission = submission_pl.to_pandas(),\n",
    "        row_id_column_name = ''\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'factor': factor,\n",
    "        'score': curr_score\n",
    "    })\n",
    "    \n",
    "    if curr_score > best_score:\n",
    "        best_score = curr_score\n",
    "        best_factor = factor\n",
    "\n",
    "print(f'Best scaling factor: {best_factor}')\n",
    "print(f'Best score: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9dc8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation code\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "\n",
    "MIN_INVESTMENT = 0\n",
    "MAX_INVESTMENT = 2\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n",
    "\n",
    "    This metric penalizes strategies that take on significantly more volatility\n",
    "    than the underlying market.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated adjusted Sharpe ratio.\n",
    "    \"\"\"\n",
    "\n",
    "    if not pandas.api.types.is_numeric_dtype(submission['prediction']):\n",
    "        raise ParticipantVisibleError('Predictions must be numeric')\n",
    "\n",
    "    solution = solution\n",
    "    solution['position'] = submission['prediction']\n",
    "\n",
    "    if solution['position'].max() > MAX_INVESTMENT:\n",
    "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].max()} exceeds maximum of {MAX_INVESTMENT}')\n",
    "    if solution['position'].min() < MIN_INVESTMENT:\n",
    "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].min()} below minimum of {MIN_INVESTMENT}')\n",
    "\n",
    "    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n",
    "\n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n",
    "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1\n",
    "    strategy_std = solution['strategy_returns'].std()\n",
    "\n",
    "    trading_days_per_yr = 252\n",
    "    if strategy_std == 0:\n",
    "        raise ParticipantVisibleError('Division by zero, strategy std is zero')\n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "    # Calculate market return and volatility\n",
    "    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod()\n",
    "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1\n",
    "    market_std = solution['forward_returns'].std()\n",
    "\n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "    if market_volatility == 0:\n",
    "        raise ParticipantVisibleError('Division by zero, market std is zero')\n",
    "\n",
    "    # Calculate the volatility penalty\n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "    vol_penalty = 1 + excess_vol\n",
    "\n",
    "    # Calculate the return penalty\n",
    "    return_gap = max(\n",
    "        0,\n",
    "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
    "    )\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "    return min(float(adjusted_sharpe), 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829a03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8_990, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>forward_returns_lag_1</th><th>forward_returns_lag_2</th><th>forward_returns_lag_3</th><th>forward_returns_lag_4</th><th>forward_returns_lag_5</th><th>forward_returns_lag_10</th><th>forward_returns_lag_20</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td></tr><tr><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td></tr><tr><td>-0.008495</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td></tr><tr><td>-0.009624</td><td>-0.008495</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td></tr><tr><td>0.004662</td><td>-0.009624</td><td>-0.008495</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td><td>-0.002421</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>-0.002896</td><td>0.008357</td><td>0.00542</td><td>-0.00741</td><td>-0.005964</td><td>0.015341</td><td>0.007798</td></tr><tr><td>0.002457</td><td>-0.002896</td><td>0.008357</td><td>0.00542</td><td>-0.00741</td><td>-0.004386</td><td>-0.001977</td></tr><tr><td>0.002312</td><td>0.002457</td><td>-0.002896</td><td>0.008357</td><td>0.00542</td><td>0.004187</td><td>0.010646</td></tr><tr><td>0.002891</td><td>0.002312</td><td>0.002457</td><td>-0.002896</td><td>0.008357</td><td>0.002279</td><td>0.003423</td></tr><tr><td>0.00831</td><td>0.002891</td><td>0.002312</td><td>0.002457</td><td>-0.002896</td><td>0.003541</td><td>0.000093</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8_990, 7)\n",
       "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ forward_retu ┆ forward_ret ┆ forward_ret ┆ forward_ret ┆ forward_ret ┆ forward_ret ┆ forward_ret │\n",
       "│ rns_lag_1    ┆ urns_lag_2  ┆ urns_lag_3  ┆ urns_lag_4  ┆ urns_lag_5  ┆ urns_lag_10 ┆ urns_lag_20 │\n",
       "│ ---          ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ f64          ┆ f64         ┆ f64         ┆ f64         ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ -0.002421    ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   │\n",
       "│ -0.002421    ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   │\n",
       "│ -0.008495    ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   │\n",
       "│ -0.009624    ┆ -0.008495   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   │\n",
       "│ 0.004662     ┆ -0.009624   ┆ -0.008495   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   ┆ -0.002421   │\n",
       "│ …            ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           │\n",
       "│ -0.002896    ┆ 0.008357    ┆ 0.00542     ┆ -0.00741    ┆ -0.005964   ┆ 0.015341    ┆ 0.007798    │\n",
       "│ 0.002457     ┆ -0.002896   ┆ 0.008357    ┆ 0.00542     ┆ -0.00741    ┆ -0.004386   ┆ -0.001977   │\n",
       "│ 0.002312     ┆ 0.002457    ┆ -0.002896   ┆ 0.008357    ┆ 0.00542     ┆ 0.004187    ┆ 0.010646    │\n",
       "│ 0.002891     ┆ 0.002312    ┆ 0.002457    ┆ -0.002896   ┆ 0.008357    ┆ 0.002279    ┆ 0.003423    │\n",
       "│ 0.00831      ┆ 0.002891    ┆ 0.002312    ┆ 0.002457    ┆ -0.002896   ┆ 0.003541    ┆ 0.000093    │\n",
       "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = [1, 2, 3, 4, 5, 10, 20]\n",
    "col = 'forward_returns'\n",
    "lagged_exprs = [\n",
    "    pl.col(col).shift(day)\n",
    "    .alias(f'{col}_lag_{day}')\n",
    "    for day in days\n",
    "]\n",
    "\n",
    "alloc = train.with_columns(lagged_exprs).select([f'{col}_lag_{day}' for day in days])\n",
    "alloc = alloc.fill_null(strategy = 'forward').fill_null(strategy = 'backward')\n",
    "target = train.select('market_forward_excess_returns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dab2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51951711, 0.51951711, 0.52162108, ..., 0.51476374, 0.51416013,\n",
       "       0.51317477], shape=(8990,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_mini_train = np.sign(target.to_numpy().ravel())\n",
    "\n",
    "mini_model = LogisticRegression()\n",
    "mini_model.fit(alloc.to_numpy(), y_mini_train)\n",
    "\n",
    "momentum_feature_values = mini_model.predict_proba(alloc.to_numpy())[:, 1]\n",
    "\n",
    "print(momentum_feature_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f102a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score of the mini-model on the validation set: 0.5191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "split = int(alloc.height * 0.8)\n",
    "\n",
    "X_mini_train = alloc.head(split)\n",
    "y_train_full = target.head(split)\n",
    "X_mini_valid = alloc.tail(-split)\n",
    "y_valid_full = target.tail(-split)\n",
    "\n",
    "y_train_binary = np.where(y_train_full.to_numpy().ravel() > 0, 1, 0)\n",
    "y_valid_binary = np.where(y_valid_full.to_numpy().ravel() > 0, 1, 0)\n",
    "\n",
    "mini_model = LogisticRegression()\n",
    "mini_model.fit(X_mini_train.to_numpy(), y_train_binary)\n",
    "\n",
    "valid_probabilities = mini_model.predict_proba(X_mini_valid.to_numpy())[:, 1]\n",
    "\n",
    "auc_score = roc_auc_score(y_valid_binary, valid_probabilities)\n",
    "print(f\"ROC AUC Score of the mini-model on the validation set: {auc_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
